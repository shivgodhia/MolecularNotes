import sys
import os
import re

# Default tag filter when none is provided
ALL_TAG_FILTER = "all"

# Helper Functions
def is_topic(file_path):
    """Checks if the given file is a topic."""
    try:
        with open(file_path, 'r') as f:
            content = f.read()
        return re.search(r"Type:.*#topic", content) is not None
    except FileNotFoundError:
        print(f"Error: File {file_path} not found.")
        return False

def get_topic_name(file_path):
    """Extracts the name of the topic from the file title."""
    return os.path.splitext(os.path.basename(file_path))[0]

def natural_sort_key(filename):
    """Generate a sort key for natural sorting, treating version numbers as hierarchical."""
    base_name = os.path.basename(filename).lower()

    def parse_part(part):
        if '.' in part and part.replace('.', '').isdigit():
            return [int(x) for x in part.split('.')]  # Split version numbers like "3.10"
        elif part.isdigit():
            return [int(part)]  # Treat integers as numbers
        return [part]  # Non-numeric parts as strings

    parts = re.split(r'(\d+(?:\.\d+)?)', base_name)
    return [subpart for part in parts for subpart in parse_part(part)]

def get_file_type(file_path):
    """Determines the type of the file (e.g., #topic, #atom, #molecule, #source)."""
    try:
        with open(file_path, 'r') as f:
            content = f.read()
        match = re.search(r"Type:\s*#(\w+)", content)
        return match.group(1) if match else None
    except FileNotFoundError:
        print(f"Error: File {file_path} not found.")
        return None

def read_file_content(file_path):
    """Reads and returns the content of a file, removing autogenerated TOC."""
    try:
        with open(file_path, 'r') as f:
            content = f.read()
        return remove_autogenerated_toc(content)
    except FileNotFoundError:
        print(f"Error: File {file_path} not found.")
        return ""

def get_unique_file_path(base_path, file_name):
    """Generate a unique file path by appending a number if the file exists."""
    base_name, ext = os.path.splitext(file_name)
    unique_file_path = os.path.join(base_path, file_name)
    counter = 1
    while os.path.exists(unique_file_path):
        unique_file_path = os.path.join(base_path, f"{base_name} ({counter}){ext}")
        counter += 1
    return unique_file_path

# Markdown Adjustments
def remove_autogenerated_toc(content):
    """Removes autogenerated table-of-contents code blocks from content."""
    return re.sub(r"```table-of-contents[\s\S]*?```", "", content, flags=re.MULTILINE)

def clean_content(content):
    """Cleans up content by removing properties, flashcard IDs, and metadata hashtags."""
    content = re.sub(r"^---[\s\S]*?---\s*", "", content, flags=re.MULTILINE)  # Remove properties block
    content = re.sub(r"^\^\d+\s*", "", content, flags=re.MULTILINE)  # Remove flashcard IDs
    content = re.sub(r"#(source|atom|molecule|topic)\b", "", content, flags=re.IGNORECASE)  # Remove hashtags
    return content.strip()


def adjust_headings(content, level):
    """Adjusts Markdown headings in the content based on the level, skipping code blocks."""
    adjusted_lines = []
    in_code_block = False

    for line in content.splitlines():
        if line.strip().startswith("```"):  # Toggle in/out of a code block
            in_code_block = not in_code_block
            adjusted_lines.append(line)
        elif not in_code_block and line.startswith("#"):  # Adjust only heading lines outside code blocks
            heading_level = len(line.split(" ")[0])  # Count the number of '#'
            new_heading_level = heading_level + level
            adjusted_lines.append("#" * new_heading_level + line[heading_level:])
        else:
            adjusted_lines.append(line)

    return "\n".join(adjusted_lines)


def count_top_level_headings(content):
    """Counts the number of top-level headings (# Header 1) in the content, excluding code blocks."""
    lines = content.splitlines()
    in_code_block = False
    header_count = 0

    for line in lines:
        if line.strip().startswith("```"):  # Toggle in/out of a code block
            in_code_block = not in_code_block
        elif not in_code_block and line.startswith("# "):  # Count headers outside code blocks
            header_count += 1

    return header_count

def get_first_top_level_heading(content):
    """Gets the first top-level heading (# Header 1) from the content, excluding code blocks."""
    in_code_block = False
    for line in content.splitlines():
        if line.strip().startswith("```"):
            in_code_block = not in_code_block
        elif line.startswith("# ") and not in_code_block:
            return line[2:].strip()
    return None

def remove_first_top_level_heading(content):
    """Removes the first top-level heading (# Header 1) from the content."""
    lines = content.splitlines()
    found_heading = False
    return "\n".join(line for line in lines if not (line.startswith("# ") and not found_heading and (found_heading := True)))

# Core Logic
def find_references_to_topic(vault_path, topic_name, tag_filter):
    """Finds all files in the vault that link to the given topic, respecting tag filters."""
    atoms, molecules, sources, subtopics = [], [], [], []

    for root, _, files in os.walk(vault_path):
        if "Compiled" in root.split(os.sep):  # Skip compiled directory
            continue
        for file in files:
            if file.endswith(".md"):
                file_path = os.path.join(root, file)
                try:
                    with open(file_path, 'r') as f:
                        content = f.read()
                    if re.search(fr"Topics:.*\[\[{re.escape(topic_name)}\]\]", content):
                        file_type = get_file_type(file_path)
                        if file_type == "topic":
                            subtopics.append(file_path)
                        elif ALL_TAG_FILTER in tag_filter or any(re.search(fr"{re.escape(tag)}\b", content) for tag in tag_filter):
                            if file_type == "atom":
                                atoms.append(file_path)
                            elif file_type == "molecule":
                                molecules.append(file_path)
                            elif file_type == "source":
                                sources.append(file_path)
                except FileNotFoundError:
                    print(f"Error: File {file_path} not found.")

    return (
        sorted(atoms, key=natural_sort_key)
        + sorted(molecules, key=natural_sort_key)
        + sorted(sources, key=natural_sort_key)
        + sorted(subtopics, key=natural_sort_key)
    )

def dfs_traverse(vault_path, topic_file, tag_filter, visited, output_lines, level=0):
    """Recursively traverses topics and references, generating structured output."""
    topic_name = get_topic_name(topic_file)
    abs_topic_path = os.path.abspath(topic_file)

    if abs_topic_path in visited:
        return  # Avoid cycles
    visited.add(abs_topic_path)

    child_files = find_references_to_topic(vault_path, topic_name, tag_filter)
    for child_file in child_files:
        child_type = get_file_type(child_file)
        child_name = get_topic_name(child_file)

        if child_type == "topic":
            output_lines.append(f"{'#' * (level + 1)} Subtopic: [[{child_name}]]\n")
            dfs_traverse(vault_path, child_file, tag_filter, visited, output_lines, level + 1)
        elif child_type in ("atom", "molecule", "source"):
            label = child_type.capitalize()
            raw_content = read_file_content(child_file)
            content = clean_content(raw_content)
            if count_top_level_headings(content) == 1:
                first_heading = get_first_top_level_heading(content)
                if first_heading != child_name:
                    output_lines.append(f"{'#' * (level + 1)} {label}: [[{child_name}]]/{first_heading}\n")
                else:
                    output_lines.append(f"{'#' * (level + 1)} {label}: [[{child_name}]]\n")
                adjusted_content = adjust_headings(remove_first_top_level_heading(content), level)
            else:
                output_lines.append(f"{'#' * (level + 1)} {label}: [[{child_name}]]\n")
                adjusted_content = adjust_headings(content, level + 1)
            output_lines.append(adjusted_content + "\n")

# Main Execution
if __name__ == "__main__":
    vault_path, file_path = sys.argv[1], sys.argv[2]
    tag_filter = sys.argv[3] if len(sys.argv) > 3 else ALL_TAG_FILTER
    if not tag_filter.strip():
        tag_filter = ALL_TAG_FILTER
    tag_filter = [f"#{tag.strip()}" if not tag.startswith("#") else tag.strip() for tag in tag_filter.split(",")] if tag_filter != ALL_TAG_FILTER else [ALL_TAG_FILTER]


    abs_file_path = os.path.abspath(os.path.join(vault_path, file_path))
    if not is_topic(abs_file_path):
        sys.exit(f"Error: The file {abs_file_path} is not a topic.")

    output_lines = [
        f"Compiled notes for [[{get_topic_name(file_path)}]]\n",
        """```table-of-contents
title:
style: nestedList
minLevel: 0
maxLevel: 0
includeLinks: true
hideWhenEmpty: false
debugInConsole: false
```\n"""
    ]

    visited = set()
    dfs_traverse(vault_path, abs_file_path, tag_filter, visited, output_lines)

    topics_dir = os.path.dirname(os.path.relpath(abs_file_path, vault_path))
    compiled_dir_path = os.path.join(vault_path, topics_dir.rsplit("Topics", 1)[0], "Compiled")
    os.makedirs(compiled_dir_path, exist_ok=True)

    tag_str = ALL_TAG_FILTER if ALL_TAG_FILTER in tag_filter else "_".join(tag.removeprefix("#") for tag in tag_filter)
    output_file_name = f"{get_topic_name(file_path)} ({tag_str}).md"
    output_file_path = os.path.join(compiled_dir_path, output_file_name)
    # Generate a unique output file path within "Compiled"
    output_file_path = get_unique_file_path(compiled_dir_path, output_file_name)
    with open(output_file_path, "w") as f:
        f.write("\n".join(output_lines))

    print(f"Compiled file generated: {output_file_path}")
